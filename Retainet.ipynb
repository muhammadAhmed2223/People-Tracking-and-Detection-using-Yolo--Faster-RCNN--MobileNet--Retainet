{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026e9e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Frame:  5\n",
      "Processing Frame:  10\n",
      "Processing Frame:  15\n",
      "Processing Frame:  20\n",
      "Processing Frame:  25\n",
      "Processing Frame:  30\n",
      "Processing Frame:  35\n",
      "Processing Frame:  40\n",
      "Processing Frame:  45\n",
      "Processing Frame:  50\n",
      "Processing Frame:  55\n",
      "Processing Frame:  60\n",
      "Processing Frame:  65\n",
      "Processing Frame:  70\n",
      "Processing Frame:  75\n",
      "Processing Frame:  80\n",
      "Processing Frame:  85\n",
      "Processing Frame:  90\n",
      "Processing Frame:  95\n",
      "Processing Frame:  100\n",
      "Processing Frame:  105\n",
      "Processing Frame:  110\n",
      "Processing Frame:  115\n",
      "Processing Frame:  120\n",
      "Processing Frame:  125\n",
      "Processing Frame:  130\n",
      "Processing Frame:  135\n",
      "Processing Frame:  140\n",
      "Processing Frame:  145\n",
      "Processing Frame:  150\n",
      "Processing Frame:  155\n",
      "Processing Frame:  160\n",
      "Processing Frame:  165\n",
      "Processing Frame:  170\n",
      "Processing Frame:  175\n",
      "Processing Frame:  180\n",
      "Processing Frame:  185\n",
      "Processing Frame:  190\n",
      "Processing Frame:  195\n",
      "Processing Frame:  200\n",
      "Processing Frame:  205\n",
      "Processing Frame:  210\n",
      "Processing Frame:  215\n",
      "Processing Frame:  220\n",
      "Processing Frame:  225\n",
      "Processing Frame:  230\n",
      "Processing Frame:  235\n",
      "Processing Frame:  240\n",
      "Processing Frame:  245\n",
      "Processing Frame:  250\n",
      "Processing Frame:  255\n",
      "Processing Frame:  260\n",
      "Processing Frame:  265\n",
      "Processing Frame:  270\n",
      "Processing Frame:  275\n",
      "Processing Frame:  280\n",
      "Processing Frame:  285\n",
      "Processing Frame:  290\n",
      "Processing Frame:  295\n",
      "Processing Frame:  300\n",
      "Processing Frame:  305\n",
      "Processing Frame:  310\n",
      "Processing Frame:  315\n",
      "Processing Frame:  320\n",
      "Processing Frame:  325\n",
      "Processing Frame:  330\n",
      "Processing Frame:  335\n",
      "Processing Frame:  340\n",
      "Processing Frame:  345\n",
      "Processing Frame:  350\n",
      "Processing Frame:  355\n",
      "Processing Frame:  360\n",
      "Processing Frame:  365\n",
      "Processing Frame:  370\n",
      "Processing Frame:  375\n",
      "Processing Frame:  380\n",
      "Processing Frame:  385\n",
      "Processing Frame:  390\n",
      "Processing Frame:  395\n",
      "Processing Frame:  400\n",
      "Processing Frame:  405\n",
      "Processing Frame:  410\n",
      "Processing Frame:  415\n",
      "Processing Frame:  420\n",
      "Processing Frame:  425\n",
      "Processing Frame:  430\n",
      "Processing Frame:  435\n",
      "Processing Frame:  440\n",
      "Processing Frame:  445\n",
      "Processing Frame:  450\n",
      "Processing Frame:  455\n",
      "Processing Frame:  460\n",
      "Processing Frame:  465\n",
      "Processing Frame:  470\n",
      "Processing Frame:  475\n",
      "Processing Frame:  480\n",
      "Processing Frame:  485\n",
      "Processing Frame:  490\n",
      "Processing Frame:  495\n",
      "Processing Frame:  500\n",
      "Processing Frame:  505\n",
      "Processing Frame:  510\n",
      "Processing Frame:  515\n",
      "Processing Frame:  520\n",
      "Processing Frame:  525\n",
      "Processing Frame:  530\n",
      "Processing Frame:  535\n",
      "Processing Frame:  540\n",
      "Processing Frame:  545\n",
      "Processing Frame:  550\n",
      "Processing Frame:  555\n",
      "Processing Frame:  560\n",
      "Processing Frame:  565\n",
      "Processing Frame:  570\n",
      "Processing Frame:  575\n",
      "Processing Frame:  580\n",
      "Processing Frame:  585\n",
      "Processing Frame:  590\n",
      "Processing Frame:  595\n",
      "Processing Frame:  600\n",
      "Processing Frame:  605\n",
      "Processing Frame:  610\n",
      "Processing Frame:  615\n",
      "Processing Frame:  620\n",
      "Processing Frame:  625\n",
      "Processing Frame:  630\n",
      "Processing Frame:  635\n",
      "Processing Frame:  640\n",
      "Processing Frame:  645\n",
      "Processing Frame:  650\n",
      "Processing Frame:  655\n",
      "Processing Frame:  660\n",
      "Processing Frame:  665\n",
      "Processing Frame:  670\n",
      "Processing Frame:  675\n",
      "Processing Frame:  680\n",
      "Processing Frame:  685\n",
      "Processing Frame:  690\n",
      "Processing Frame:  695\n",
      "Processing Frame:  700\n",
      "Processing Frame:  705\n",
      "Processing Frame:  710\n",
      "Processing Frame:  715\n",
      "Processing Frame:  720\n",
      "Processing Frame:  725\n",
      "Processing Frame:  730\n",
      "FPS: 0.290642\n",
      "Total Detections:  209  Average Confidence score:  0.599025\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the Faster R-CNN model from TensorFlow Hub\n",
    "model_url = \"https://www.kaggle.com/models/tensorflow/retinanet-resnet/frameworks/TensorFlow2/variations/101-v1-fpn-1024x1024/versions/1\"\n",
    "detector = hub.load(model_url)\n",
    "\n",
    "# Function to perform pedestrian detection on a video\n",
    "def detect_pedestrians(input_video_path, output_video_path):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Create VideoWriter for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    start_time = time.time()  # Record the start time\n",
    "    skipframes = 4\n",
    "    tempcount = 0\n",
    "    framecount = 0\n",
    "    confidence = []\n",
    "    framesProcessed = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if tempcount == skipframes:\n",
    "            tempcount = 0\n",
    "            framecount += 1\n",
    "        else:\n",
    "            framecount += 1\n",
    "            tempcount += 1\n",
    "            continue\n",
    "        \n",
    "        framesProcessed += 1\n",
    "        print(\"Processing Frame: \", framecount)\n",
    "        # Convert BGR to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Preprocess the frame to match the model's input requirements\n",
    "        image_tensor = tf.convert_to_tensor([rgb_frame], dtype=tf.uint8)\n",
    "\n",
    "        # Apply the image detector\n",
    "        detector_output = detector(image_tensor)\n",
    "\n",
    "        # Extract relevant information from the detector_output\n",
    "        num_detections = int(detector_output['num_detections'][0])\n",
    "        detection_boxes = detector_output['detection_boxes'][0].numpy()\n",
    "        detection_classes = detector_output['detection_classes'][0].numpy()\n",
    "        detection_scores = detector_output['detection_scores'][0].numpy()\n",
    "\n",
    "        # Draw bounding boxes on pedestrians\n",
    "        for i in range(num_detections):\n",
    "            if detection_scores[i] > 0.5 and detection_classes[i] == 1:  # Class index 1 corresponds to pedestrians\n",
    "                confidence.append(detection_scores[i])\n",
    "                box = detection_boxes[i]\n",
    "                ymin, xmin, ymax, xmax = box\n",
    "                ymin, xmin, ymax, xmax = int(ymin * height), int(xmin * width), int(ymax * height), int(xmax * width)\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, 'Pedestrian', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)\n",
    "\n",
    "        # Write the frame with bounding boxes to the output videoq\n",
    "        out.write(frame)\n",
    "\n",
    "        # Display the frame with bounding boxes\n",
    "        cv2.imshow('Pedestrian Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    end_time = time.time()  # Record the end time\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    fps = framesProcessed/total_time\n",
    "    print(\"FPS: {:2f}\".format(fps))\n",
    "    confidenceAvg = np.mean(confidence)\n",
    "    \n",
    "    print(\"Total Detections: \", len(confidence), \" Average Confidence score: \", confidenceAvg)\n",
    "    \n",
    "    # Release video capture and writer\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Specify the input and output video paths\n",
    "input_video_path = 'Dataset/pedestrian.mp4'\n",
    "output_video_path = 'FasterRCNN_output_video.avi'\n",
    "\n",
    "# Perform pedestrian detection on the input video and display bounding boxes\n",
    "detect_pedestrians(input_video_path, output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960fc27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
